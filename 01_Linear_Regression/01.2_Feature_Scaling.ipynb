{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling & Feature Engineering\n",
    "## Feature Scaling\n",
    "Trong các thuật toán Machine Learning, các model dự đoán output từ training examples trong tập training data.  \n",
    "Các input features có thể nhận giá trị trong các miền khác nhau. Ví dụ trong dataset về giá nhà dựa trên các đặc điểm của ngôi nhà: diện tích nhà nhận giá trị từ 2000 đến 16000 m2, trong khi đó số lượng phòng ngủ chỉ từ 1 đến 5 phòng. Điều này khiến Gradient Descend cần nhiều thời gian hơn để tìm được local minimum của cost function.  \n",
    "**Mục tiêu:** Chuẩn hóa (scale) dữ liệu trước khi training model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling Methods\n",
    "2 phương pháp thường dùng để scale dữ liệu:\n",
    "1. **Min-Max Normalization (Normalization)**\n",
    "Normalization là phương pháp scale dữ liệu từ miền giá trị bất kỳ sang miền giá trị trong khoảng từ 0 đến 1.  \n",
    "Công thức:\n",
    "$$x_{i}^{'}=\\frac{x_{i}-min}{max-min}$$\n",
    "Trong đó min và max lần lượt là giá trị nhỏ nhất và lớn nhất của feature $x_{i}$   \n",
    "Chúng ta có thể normalize dữ liệu sử dụng **MinMaxScaler** trong thư viện scikit-learn.\n",
    "VD: Ta có $2000 \\leq x_{1} \\leq 16000$ thì giá trị min và max của $x_{i}$ là 2000 và 16000   \n",
    "2. **Z-score Normalization (Standardization)**\n",
    "Standardization là phương pháp scale dữ liệu về phân phối chuẩn tắc (standard normal distribution), tức là phân phối với mean bằng 0 và deviation bằng 1.  \n",
    "Công thức:\n",
    "$$x_{i}^{'}=\\frac{x-\\mu_{i}}{\\sigma_{i}}$$\n",
    "Trong đó $\\mu_{i}$ và $\\sigma_{i}$ lần lượt là mean và deviation của feature $x_{i}$   \n",
    "Chúng ta có thể standardize dữ liệu sử dụng **StandardScaler** trong thư viện scikit-learn.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample implementation of data scaling with MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Load data\n",
    "data = ...\n",
    "scaler = MinMaxScaler()\n",
    "# fit scaler to data and normalize\n",
    "normalized = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample implementation of data scaling with StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "data = ...\n",
    "scaler = StandardScaler()\n",
    "standardized = scaler.fit_transform(data)\n",
    "# We can revert the scaled data to the original by using inverse_tranform()\n",
    "inv = scaler.inverse_transform(normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "Feature Engineering là công việc tạo ra input features phù hợp bằng cách biến đổi hoặc kết hợp các features có sẵn, nhằm có được mô hình tốt hơn.  \n",
    "Có nhiều kỹ thuật Feature Engineering, tuy nhiên cho đến hiện tại mình chưa tìm hiểu kỹ từng kỹ thuật. Mình sẽ quay lại phần này sau."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
