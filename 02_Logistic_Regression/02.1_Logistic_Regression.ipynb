{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "Logistic Regression là một model cho output là các xác suất (probability). Logistic Regression thường được sử dụng cho bài toán phân loại (classification).  \n",
    "Giả dụ, chúng ta có data về kích thước của các khối u và khối u nào là u lành tính, u ác tính. Để phân loại một khối u dựa trên kích thước của nó, ta tính xác suất khối u đó là u ác tính, sau đó so sánh xác suất đó với một ngưỡng xác định (threshold). VD: Threshold là 0.5, nếu xác suất khối u đó ác tính là 0.34 thì khối u là u lành tính.   \n",
    "Tuy nhiên, làm thế nào để tính được xác suất là u lành tính/ác tính khi có dữ liệu về kích thước? Chúng ta dùng hàm *tanh* hoặc hàm *sigmoid*. Ở đây, mình chỉ trình bày về hàm *sigmoid*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid Function\n",
    "*sigmoid* function, hay còn gọi là logistic function, là một hàm map các giá trị dự đoán đến giá trị xác suất từ 0 đến 1.  \n",
    "Công thức:\n",
    "$$\\sigma(z)=\\frac{1}{1+e^{-z}}$$\n",
    "Xét các trường hợp:   \n",
    "$z \\rightarrow \\infty \\Rightarrow \\sigma(z) \\rightarrow 1$   \n",
    "$z \\rightarrow -\\infty \\Rightarrow \\sigma(z) \\rightarrow 0$    \n",
    "$z = 0 \\Rightarrow \\sigma(z) = 0.5$  \n",
    "![graph: sigmoid function and its derivative](image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model\n",
    "Output của Logistic Regression model được viết dưới dạng:  \n",
    "$$\\overrightarrow{y}=\\sigma(\\overrightarrow{w}\\cdot\\overrightarrow{x}+b)=\\frac{1}{1+e^{-(\\overrightarrow{w}\\cdot\\overrightarrow{x}+b)}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Boundary\n",
    "Decision Boundary là ranh giới phân biệt các lớp (classes) khác nhau.   \n",
    "Để xác định decision boundary, chúng ta cần:\n",
    "1. Đặt ra threshold cho predicted output $\\hat{y}$   \n",
    "VD: Trong bài toán phân loại khối u nói trên (một bài toán binary classification điển hình), ta đặt threshold: Nếu predicted output lớn hơn hoặc bằng 50% thì khối u đó ác tính, hay nếu $\\hat{y}=\\sigma(z) \\geq 0.5$ thì $y=1$, với $z = \\overrightarrow{w}\\cdot\\overrightarrow{x}+b$\n",
    "2. Tính $\\hat{x}$ (decision boundary)   \n",
    "VD: $\\hat{y}=\\sigma(z)=\\sigma(\\overrightarrow{w}\\cdot\\overrightarrow{x}+b) \\geq 0.5 \\Longleftrightarrow z \\geq 0$   \n",
    "Sau khi tìm được $\\overrightarrow{w}$ và $b$ tối ưu, giải $\\overrightarrow{x}$ để $z=0$:    \n",
    "$z=\\overrightarrow{w}\\cdot\\overrightarrow{x}+b=0$  \n",
    "VD: Ta có $\\sigma(z)=\\sigma(w_{1}x_{1}^2+w_{2}x_{2}^2+b)$ và $w_{1}=w_{2}=1, b=-1$  \n",
    "$\\Rightarrow$ Decision boundary: $x_{1}^2+x_{2}^2-1=0$ (Đường tròn có  tâm tại gốc tọa độ và bán kính bằng 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Function\n",
    "Định nghĩa: $L(f_{\\overrightarrow{w},b}(\\overrightarrow{x}^{(i)}),y^{(i)})$ là loss (sai khác) trên mỗi training example; cost trên toàn bộ dataset là tổng loss trên tất cả training examples.   \n",
    "$$L(f_{\\overrightarrow{w},b}(\\overrightarrow{x}^{(i)}),y^{(i)})=\\begin{cases}\n",
    "-log(f_{\\overrightarrow{w},b}(\\overrightarrow{x}^{(i)})) \\text{ if } y^{(i)}=1\\\\\n",
    "-log(1-f_{\\overrightarrow{w},b}(\\overrightarrow{x}^{(i)})) \\text{ if } y^{(i)}=0\\\\\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descend for Logistic Regression"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
